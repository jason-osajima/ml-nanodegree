{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udacity Machine Learning Engineer Nanodegree Project 5 \n",
    "=============\n",
    "\n",
    "Deep Learning for Satellite Image Recognition\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring and Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will extract and investigate the images from the SAT-6 dataset. Information about the dataset is available here: \n",
    "    \n",
    "    http://csc.lsu.edu/~saikat/deepsat/ \n",
    "\n",
    "The dataset contains 405,000 satellite images, and is separated into 324,000 images for the training dataset and 81,000 for the testing dataset. We start by opening the mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory contains 'sat-6-full.mat'\n"
     ]
    }
   ],
   "source": [
    "def open_mat(filename):\n",
    "    #opens the SAT6 dataset, which is a .mat file.\n",
    "    if os.path.isfile(filename): \n",
    "        print (\"Current working directory contains %r\" % filename)\n",
    "        mat_contents = sio.loadmat(filename)\n",
    "        print (\"SAT6 loaded successfully.\")\n",
    "    else:\n",
    "        print (\"Download %r to current working directory\" % filename)\n",
    "    return mat_contents\n",
    "\n",
    "mat_sat_6 = 'sat-6-full.mat'\n",
    "\n",
    "sat_6 = open_mat(mat_sat_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def investigate_dict(a, b):\n",
    "    keys_list = a.keys()\n",
    "    keys_str = ', '.join(keys_list)\n",
    "    lst = []\n",
    "    print(\"File is a %r, with keys %r.\" % (type(a), keys_str))\n",
    "    for k in b:\n",
    "        array = a.get(k)\n",
    "        print('%r has dimensions %r' % (k, array.shape))\n",
    "        lst.append(array)\n",
    "    return lst\n",
    "\n",
    "sets = ['train_x', 'train_y', 'test_x', 'test_y']\n",
    "\n",
    "raw_x_train, raw_y_train, raw_x_test, raw_y_test = investigate_dict(sat_6, sets)\n",
    "print(sat_6['annotations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 324,000 training images and 81,000 testing images. Each image is 28x28, meaning each picture has 784 pixels. Each image also has 4 layers (Red, Green, Blue and Near-Infared), and is labeled with a binary vector. The vector has 6 elements and each element corresponds with the six classes the image could belong to (buildings, barren land, trees, roads, buildings and water bodies). \n",
    "\n",
    "Let's change the dimensions of the array so that the image index is the first dimension, the type of layer is the second, and the pixels are the third. This will make it simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def change_dim(a):\n",
    "    lst = []\n",
    "    \n",
    "    for i in a:\n",
    "        \n",
    "        if len(i.shape) == 4:\n",
    "            i_2 = np.rollaxis(i, 3)\n",
    "            i_3 = np.rollaxis(i_2, 3, start = 1)\n",
    "            lst.append(i_3)\n",
    "        \n",
    "        elif len(i.shape) == 2:\n",
    "            i_4 = np.rollaxis(i, 1)\n",
    "            lst.append(i_4)\n",
    "        \n",
    "        else:\n",
    "            print('Dimensions of arrays do not work')\n",
    "    \n",
    "    return lst\n",
    "\n",
    "\n",
    "raw = [raw_x_train, raw_y_train, raw_x_test, raw_y_test]\n",
    "\n",
    "switch_x_train, switch_y_train, switch_x_test, switch_y_test = change_dim(raw)\n",
    "\n",
    "print(switch_x_train.shape)\n",
    "print(switch_y_train.shape)\n",
    "print(switch_x_test.shape)\n",
    "print(switch_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view a sample of the images and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_images(labels, x_data, y_data, n):\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        r = np.random.choice(len(x_data))\n",
    "        #Create an rgb array\n",
    "        rgbArray = np.zeros((28,28,3), 'uint8')\n",
    "        rgbArray[..., 0] = x_data[r,0,...]\n",
    "        rgbArray[..., 1] = x_data[r,1,...]\n",
    "        rgbArray[..., 2] = x_data[r,2,...]\n",
    "        img = Image.fromarray(rgbArray)\n",
    "        out = img.resize((48, 48))\n",
    "        display(out)\n",
    "\n",
    "        #returns the index of 1 from the label array\n",
    "        label_index = y_data[r].tolist().index(1)\n",
    "        print(labels[label_index])\n",
    "\n",
    "land_cover = ['buildings', 'barren_land', 'trees', 'grassland', 'roads', 'water_bodies']\n",
    "\n",
    "sample_images(land_cover, switch_x_train, switch_y_train, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will divide our dataset into training, testing, and cross validation sets. Currently,  80% of the dataset is reserved for training, and 20% of the dataset is reserved for testing. To prevent bias, we will concatenate the training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine original train and test set together.\n",
    "X_all = np.concatenate((switch_x_train, switch_x_test), axis=0)\n",
    "y_all = np.concatenate((switch_y_train, switch_y_test), axis = 0)\n",
    "\n",
    "#Shuffle the data\n",
    "perm = random.permutation(len(X_all))\n",
    "X_all_shuffled = X_all[perm]\n",
    "y_all_shuffled = y_all[perm]\n",
    "\n",
    "#Verify that the labels and images are still correct\n",
    "sample_images(land_cover, X_all_shuffled, y_all_shuffled, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the image and label pairs have been maintained after shuffling. Since it would be computationally expensive to use k-fold cross validation to train a deep learning architecture with a large amount of training examples, we will create a simple, hold-out cross validation set as well as a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
